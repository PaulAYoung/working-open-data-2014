{
 "metadata": {
  "name": "",
  "signature": "sha256:f816c2b9e658ead0cab8a896dab2330d9cacd5cd6b3e06ec3bab2563058988f0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Exercise"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this exercise, reproduce some of the findings from [What Makes Houston the Next Great American City? | Travel | Smithsonian](http://www.smithsonianmag.com/travel/what-makes-houston-the-next-great-american-city-4870584/), specifically the calculation represented in\n",
      "\n",
      "![Alt text](http://thumbs.media.smithsonianmag.com//filer/Houston-diversity-3.jpg__600x0_q85_upscale.jpg \"Optional title\")\n",
      "\n",
      "whose caption is\n",
      "\n",
      "<blockquote>To assess the parity of the four major U.S. ethnic and racial groups, Rice University researchers used a scale called the Entropy Index. It ranges from 0 (a population has just one group) to 1 (all groups are equivalent). Edging New York for the most balanced diversity, Houston had an Entropy Index of 0.874 (orange bar).</blockquote>\n",
      "\n",
      "The research report by *Smithsonian Magazine* is\n",
      "[Houston Region Grows More Racially/Ethnically Diverse, With Small Declines in Segregation: A Joint Report Analyzing Census Data from 1990, 2000, and 2010](http://kinder.rice.edu/uploadedFiles/Urban_Research_Center/Media/Houston%20Region%20Grows%20More%20Ethnically%20Diverse%202-13.pdf) by the Kinder Institute for Urban Research & the Hobby Center for the Study of Texas.  \n",
      "\n",
      "In the report, you'll find the following quotes:\n",
      "\n",
      "<blockquote>How does Houston\u2019s racial/ethnic diversity compare to the racial/ethnic\n",
      "diversity of other large metropolitan areas? The Houston metropolitan\n",
      "area is the most racially/ethnically diverse.</blockquote>\n",
      "\n",
      "....\n",
      "\n",
      "<blockquote>Houston is one of the most racially/ethnically diverse metropolitan\n",
      "areas in the nation as well. *It is the most diverse of the 10 largest\n",
      "U.S. metropolitan areas.* [emphasis mine] Unlike the other large metropolitan areas, all\n",
      "four major racial/ethnic groups have substantial representation in\n",
      "Houston with Latinos and Anglos occupying roughly equal shares of the\n",
      "population.</blockquote>\n",
      "\n",
      "....\n",
      "\n",
      "<blockquote>Houston has the highest entropy score of the 10 largest metropolitan\n",
      "areas, 0.874. New York is a close second with a score of 0.872.</blockquote>\n",
      "\n",
      "....\n",
      "\n",
      "Your task is:\n",
      "\n",
      "1. Tabulate all the metropolian/micropolitan statistical areas.  Remember that you have to group various entities that show up separately in the Census API but which belong to the same area.  You should find 942 metropolitan/micropolitan statistical areas in the 2010 Census.\n",
      "\n",
      "1. Calculate the normalized Shannon index (`entropy5`) using the categories of White, Black, Hispanic, Asian, and Other as outlined in the [Day_07_G_Calculating_Diversity notebook](http://nbviewer.ipython.org/github/rdhyee/working-open-data-2014/blob/master/notebooks/Day_07_G_Calculating_Diversity.ipynb#Converting-to-Racial-Dot-Map-Categories) \n",
      "\n",
      "1. Calculate the normalized Shannon index (`entropy4`) by not considering the Other category.  In other words, assume that the the total population is the sum of White, Black, Hispanic, and Asian.\n",
      "\n",
      "1. Figure out how exactly the entropy score was calculated in the report from Rice University. Since you'll find that the entropy score reported matches neither `entropy5` nor `entropy4`, you'll need to play around with the entropy calculation to figure how to use 4 categories to get the score for Houston to come out to \"0.874\" and that for NYC to be \"0.872\".  [I **think** I've done so and get 0.873618 and \n",
      "0.872729 respectively.]\n",
      "\n",
      "1. Add a calculation of the [Gini-Simpson diversity index](https://en.wikipedia.org/wiki/Diversity_index#Gini.E2.80.93Simpson_index) using the five categories of White, Black, Hispanic, Asian, and Other.\n",
      "\n",
      "1. Note where the Bay Area stands in terms of the diversity index.\n",
      "\n",
      "For bonus points:\n",
      "\n",
      "* make a bar chart in the style used in the Smithsonian Magazine\n",
      "\n",
      "Deliverable:\n",
      "\n",
      "1. You will need to upload your notebook to a gist and render the notebook in nbviewer and then enter the nbviewer URL (e.g., http://nbviewer.ipython.org/gist/rdhyee/60b6c0b0aad7fd531938)\n",
      "2. On bCourses, upload the CSV version of your `msas_df`.\n",
      "\n",
      "**HAVE FUN: ASK QUESTIONS AND WORK TOGETHER**"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Constraints"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Below is testing code to help make sure you are on the right track.  A key assumption made here is that you will end up with a Pandas DataFrame called `msas_df`, indexed by the FIPS code of a metropolitan/micropolitan area (e.g., Houston's code is 26420) and with the the following columns:\n",
      "\n",
      "* Total\n",
      "* White\n",
      "* Black\n",
      "* Hispanic\n",
      "* Asian\n",
      "* Other\n",
      "* p_White\n",
      "* p_Black\n",
      "* p_Hispanic\n",
      "* p_Asian\n",
      "* p_Other\n",
      "* entropy4\n",
      "* entropy5\n",
      "* entropy_rice\n",
      "* gini_simpson\n",
      "\n",
      "You should have 942 rows, one for each MSA.  You can compare your results for `entropy5`, `entropy_rice` with mine."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#imports\n",
      "import census\n",
      "import us\n",
      "import settings\n",
      "from pandas import DataFrame\n",
      "from itertools import islice\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = census.Census(key = settings.CENSUS_KEY)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_metropolitan(fields=\"NAME\"):\n",
      "    \"\"\"\n",
      "    Allows pulling of info about metropolitan areas\n",
      "    \"\"\"\n",
      "    for state in us.STATES:\n",
      "        geo = {\n",
      "               \"for\": \"metropolitan statistical area/micropolitan statistical area:*\",\n",
      "               \"in\": \"state:{}\".format(state.fips)\n",
      "        }\n",
      "        for met_area in c.sf1.get(fields, geo):\n",
      "            yield met_area"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get census data\n",
      "\n",
      "#define fields to pull\n",
      "field_dict= {\n",
      "    'NAME': \"Name\",\n",
      "    'P0050001': \"Total\",\n",
      "    'P0050003': \"White\",\n",
      "    'P0050004': \"Black\",\n",
      "    'P0050006': \"Asian\",\n",
      "    'P0050010': \"Hispanic\",\n",
      "    'P0050005': \"Native American\",\n",
      "    'P0050007': \"Hawaiian/Pacific Islander\",\n",
      "    'P0050008': \"Other Race\",\n",
      "    'P0050009': \"Multi\"\n",
      "\n",
      "    }\n",
      "fields = list(field_dict.keys())\n",
      "metro_areas = get_metropolitan(fields)\n",
      "\n",
      "# testing code\n",
      "#for i in islice(metro_areas, 5):\n",
      "#    print i\n",
      "r = list(metro_areas)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pull data into dataframe\n",
      "others = [\"Native American\", \"Hawaiian/Pacific Islander\", \"Other Race\" , \"Multi\"]\n",
      "#others is a list of the categories that are combined into an other group\n",
      "df = DataFrame(r)\n",
      "df = df.rename(columns=field_dict)\n",
      "df = df.rename(columns={\"metropolitan statistical area/micropolitan statistical area\": \"met_group\"})\n",
      "df[others + [\"Total\", \"White\", \"Black\", \"Asian\", \"Hispanic\"]] =\\\n",
      "    df[others + [\"Total\", \"White\", \"Black\", \"Asian\", \"Hispanic\"]].astype('int')\n",
      "df[\"Other\"] = df.apply(lambda r:r[\"Native American\"] + r[\"Hawaiian/Pacific Islander\"] + \\\n",
      "                       r[\"Other Race\"] + r[\"Multi\"], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Name</th>\n",
        "      <th>Total</th>\n",
        "      <th>White</th>\n",
        "      <th>Black</th>\n",
        "      <th>Native American</th>\n",
        "      <th>Asian</th>\n",
        "      <th>Hawaiian/Pacific Islander</th>\n",
        "      <th>Other Race</th>\n",
        "      <th>Multi</th>\n",
        "      <th>Hispanic</th>\n",
        "      <th>met_group</th>\n",
        "      <th>state</th>\n",
        "      <th>Other</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>       Albertville, AL Micro Area</td>\n",
        "      <td>   93019</td>\n",
        "      <td>  78060</td>\n",
        "      <td>   1389</td>\n",
        "      <td>  570</td>\n",
        "      <td>   475</td>\n",
        "      <td>  63</td>\n",
        "      <td>  63</td>\n",
        "      <td>  1161</td>\n",
        "      <td> 11238</td>\n",
        "      <td> 10700</td>\n",
        "      <td> 01</td>\n",
        "      <td>  1857</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>    Alexander City, AL Micro Area</td>\n",
        "      <td>   53155</td>\n",
        "      <td>  36442</td>\n",
        "      <td>  14606</td>\n",
        "      <td>  159</td>\n",
        "      <td>   211</td>\n",
        "      <td>   2</td>\n",
        "      <td>  29</td>\n",
        "      <td>   434</td>\n",
        "      <td>  1272</td>\n",
        "      <td> 10760</td>\n",
        "      <td> 01</td>\n",
        "      <td>   624</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>   Anniston-Oxford, AL Metro Area</td>\n",
        "      <td>  118572</td>\n",
        "      <td>  87285</td>\n",
        "      <td>  24177</td>\n",
        "      <td>  480</td>\n",
        "      <td>   830</td>\n",
        "      <td>  94</td>\n",
        "      <td> 109</td>\n",
        "      <td>  1704</td>\n",
        "      <td>  3893</td>\n",
        "      <td> 11500</td>\n",
        "      <td> 01</td>\n",
        "      <td>  2387</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>    Auburn-Opelika, AL Metro Area</td>\n",
        "      <td>  140247</td>\n",
        "      <td>  97900</td>\n",
        "      <td>  31674</td>\n",
        "      <td>  397</td>\n",
        "      <td>  3615</td>\n",
        "      <td>  66</td>\n",
        "      <td> 164</td>\n",
        "      <td>  1860</td>\n",
        "      <td>  4571</td>\n",
        "      <td> 12220</td>\n",
        "      <td> 01</td>\n",
        "      <td>  2487</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Birmingham-Hoover, AL Metro Area</td>\n",
        "      <td> 1128047</td>\n",
        "      <td> 733656</td>\n",
        "      <td> 317019</td>\n",
        "      <td> 2857</td>\n",
        "      <td> 13748</td>\n",
        "      <td> 319</td>\n",
        "      <td> 970</td>\n",
        "      <td> 10948</td>\n",
        "      <td> 48530</td>\n",
        "      <td> 13820</td>\n",
        "      <td> 01</td>\n",
        "      <td> 15094</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "                               Name    Total   White   Black  Native American  \\\n",
        "0        Albertville, AL Micro Area    93019   78060    1389              570   \n",
        "1     Alexander City, AL Micro Area    53155   36442   14606              159   \n",
        "2    Anniston-Oxford, AL Metro Area   118572   87285   24177              480   \n",
        "3     Auburn-Opelika, AL Metro Area   140247   97900   31674              397   \n",
        "4  Birmingham-Hoover, AL Metro Area  1128047  733656  317019             2857   \n",
        "\n",
        "   Asian  Hawaiian/Pacific Islander  Other Race  Multi  Hispanic met_group  \\\n",
        "0    475                         63          63   1161     11238     10700   \n",
        "1    211                          2          29    434      1272     10760   \n",
        "2    830                         94         109   1704      3893     11500   \n",
        "3   3615                         66         164   1860      4571     12220   \n",
        "4  13748                        319         970  10948     48530     13820   \n",
        "\n",
        "  state  Other  \n",
        "0    01   1857  \n",
        "1    01    624  \n",
        "2    01   2387  \n",
        "3    01   2487  \n",
        "4    01  15094  "
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "met_group = df.groupby([df.met_group, df.Name])\n",
      "msas_df = met_group[\"Total\", \"White\", \"Black\", \"Asian\", \"Hispanic\", \"Other\"].sum()\n",
      "#msas_df.set_index(msas_df.met_group)\n",
      "msas_df[\"met_group\"] = [i[0] for i in  msas_df.index]\n",
      "msas_df[\"Name\"] = [i[1] for i in  msas_df.index]\n",
      "msas_df.set_index(msas_df.met_group, inplace=True)\n",
      "msas_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Total</th>\n",
        "      <th>White</th>\n",
        "      <th>Black</th>\n",
        "      <th>Asian</th>\n",
        "      <th>Hispanic</th>\n",
        "      <th>Other</th>\n",
        "      <th>met_group</th>\n",
        "      <th>Name</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>met_group</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>10020</th>\n",
        "      <td>  57999</td>\n",
        "      <td>  46305</td>\n",
        "      <td>  8246</td>\n",
        "      <td> 1148</td>\n",
        "      <td>  1381</td>\n",
        "      <td>  919</td>\n",
        "      <td> 10020</td>\n",
        "      <td> Abbeville, LA Micro Area</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10100</th>\n",
        "      <td>  40602</td>\n",
        "      <td>  37774</td>\n",
        "      <td>   192</td>\n",
        "      <td>  358</td>\n",
        "      <td>   554</td>\n",
        "      <td> 1724</td>\n",
        "      <td> 10100</td>\n",
        "      <td>  Aberdeen, SD Micro Area</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10140</th>\n",
        "      <td>  72797</td>\n",
        "      <td>  59282</td>\n",
        "      <td>   762</td>\n",
        "      <td>  995</td>\n",
        "      <td>  6272</td>\n",
        "      <td> 5486</td>\n",
        "      <td> 10140</td>\n",
        "      <td>  Aberdeen, WA Micro Area</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10180</th>\n",
        "      <td> 165252</td>\n",
        "      <td> 112735</td>\n",
        "      <td> 11549</td>\n",
        "      <td> 2110</td>\n",
        "      <td> 35108</td>\n",
        "      <td> 3750</td>\n",
        "      <td> 10180</td>\n",
        "      <td>   Abilene, TX Metro Area</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10220</th>\n",
        "      <td>  37492</td>\n",
        "      <td>  25973</td>\n",
        "      <td>   879</td>\n",
        "      <td>  244</td>\n",
        "      <td>  1523</td>\n",
        "      <td> 8873</td>\n",
        "      <td> 10220</td>\n",
        "      <td>       Ada, OK Micro Area</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "            Total   White  Black  Asian  Hispanic  Other met_group  \\\n",
        "met_group                                                            \n",
        "10020       57999   46305   8246   1148      1381    919     10020   \n",
        "10100       40602   37774    192    358       554   1724     10100   \n",
        "10140       72797   59282    762    995      6272   5486     10140   \n",
        "10180      165252  112735  11549   2110     35108   3750     10180   \n",
        "10220       37492   25973    879    244      1523   8873     10220   \n",
        "\n",
        "                               Name  \n",
        "met_group                            \n",
        "10020      Abbeville, LA Micro Area  \n",
        "10100       Aberdeen, SD Micro Area  \n",
        "10140       Aberdeen, WA Micro Area  \n",
        "10180        Abilene, TX Metro Area  \n",
        "10220            Ada, OK Micro Area  "
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get percentges\n",
      "for group in [\"White\", \"Black\", \"Asian\", \"Hispanic\", \"Other\"]:\n",
      "    msas_df[\"p_{}\".format(group)] = msas_df[group].astype('float')/msas_df[\"Total\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def entropy(series):\n",
      "    \"\"\"Normalized Shannon Index\"\"\"\n",
      "    # a series in which all the entries are equal should result in normalized entropy of 1.0\n",
      "    \n",
      "    # eliminate 0s\n",
      "    series1 = series[series!=0]\n",
      "\n",
      "    # if len(series) < 2 (i.e., 0 or 1) then return 0\n",
      "    \n",
      "    if len(series) > 1:\n",
      "        # calculate the maximum possible entropy for given length of input series\n",
      "        max_s = -np.log(1.0/len(series))\n",
      "    \n",
      "        total = float(sum(series1))\n",
      "        p = series1.astype('float')/float(total)\n",
      "        return sum(-p*np.log(p))/max_s\n",
      "    else:\n",
      "        return 0.0\n",
      "\n",
      "def rice_entropy(series):\n",
      "    \"Calculate rice entropy\"\n",
      "    # a series in which all the entries are equal should result in normalized entropy of 1.0\n",
      "    \n",
      "    # eliminate 0s\n",
      "    series1 = series[series!=0]\n",
      "\n",
      "    # if len(series) < 2 (i.e., 0 or 1) then return 0\n",
      "    \n",
      "    if len(series) > 1:\n",
      "        # calculate the maximum possible entropy for given length of input series\n",
      "        max_s = -np.log(1.0/len(series))\n",
      "    \n",
      "        total = float(sum(series1))\n",
      "        p = series1\n",
      "        return sum(-p*np.log(p))/max_s\n",
      "    else:\n",
      "        return 0.0\n",
      "\n",
      "def gini_simpson(series):\n",
      "    simpson = 0\n",
      "    for i in series:\n",
      "        simpson += np.square(i)\n",
      "    return 1-simpson"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "msas_df['entropy5'] = msas_df[[\"White\", \"Black\", \"Asian\", \"Hispanic\", \"Other\"]].apply(entropy, axis=1)\n",
      "msas_df['entropy4'] = msas_df[[\"White\", \"Black\", \"Asian\", \"Hispanic\"]].apply(entropy, axis=1)\n",
      "msas_df['entropy_rice'] = msas_df[[\"p_White\", \"p_Black\", \"p_Asian\", \"p_Hispanic\"]].apply(rice_entropy, axis=1)\n",
      "msas_df['gini_simpson'] = msas_df[[\"p_White\", \"p_Black\", \"p_Asian\", \"p_Hispanic\", \"p_Other\"]].apply(gini_simpson, axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Testing code\n",
      "\n",
      "def to_unicode(vals):\n",
      "    return [unicode(v) for v in vals]\n",
      "\n",
      "def test_msas_df(msas_df):\n",
      "\n",
      "    min_set_of_columns =  set(['Asian','Black','Hispanic', 'Other', 'Total', 'White',\n",
      "     'entropy4', 'entropy5', 'entropy_rice', 'gini_simpson','p_Asian', 'p_Black',\n",
      "     'p_Hispanic', 'p_Other','p_White'])  \n",
      "    \n",
      "    assert min_set_of_columns & set(msas_df.columns) == min_set_of_columns\n",
      "    \n",
      "    # https://www.census.gov/geo/maps-data/data/tallies/national_geo_tallies.html\n",
      "    # 366 metro areas\n",
      "    # 576 micropolitan areas\n",
      "    \n",
      "    assert len(msas_df) == 942  \n",
      "    \n",
      "    # total number of people in metro/micro areas\n",
      "    \n",
      "    assert msas_df.Total.sum() == 289261315\n",
      "    assert msas_df['White'].sum() == 180912856\n",
      "    assert msas_df['Other'].sum() == 8540181\n",
      "    \n",
      "    # list of msas in descendng order by entropy_rice \n",
      "    # calculate the top 10 metros by population\n",
      "    top_10_metros = msas_df.sort_index(by='Total', ascending=False)[:10]\n",
      "    \n",
      "    msa_codes_in_top_10_pop_sorted_by_entropy_rice = list(top_10_metros.sort_index(by='entropy_rice', \n",
      "                                                ascending=False).index) \n",
      "    \n",
      "    assert to_unicode(msa_codes_in_top_10_pop_sorted_by_entropy_rice)== [u'26420', u'35620', u'47900', u'31100', u'19100', \n",
      "        u'33100', u'16980', u'12060', u'37980', u'14460']\n",
      "\n",
      "\n",
      "    top_10_metro = msas_df.sort_index(by='Total', ascending=False)[:10]\n",
      "    \n",
      "    list(top_10_metro.sort_index(by='entropy_rice', ascending=False)['entropy5'])\n",
      "    \n",
      "    np.testing.assert_allclose(top_10_metro.sort_index(by='entropy_rice', ascending=False)['entropy5'], \n",
      "    [0.79628076626851163, 0.80528601550164602, 0.80809418318973791, 0.7980698349711991,\n",
      "     0.75945930510650161, 0.74913610558765376, 0.73683277781032397, 0.72964862063970914,\n",
      "     0.64082509648457675, 0.55697288400004963])\n",
      "    \n",
      "    np.testing.assert_allclose(top_10_metro.sort_index(by='entropy_rice', ascending=False)['entropy_rice'],\n",
      "    [0.87361766576115552,\n",
      "     0.87272877244078051,\n",
      "     0.85931803868749834,\n",
      "     0.85508015237749468,\n",
      "     0.82169723530719896,\n",
      "     0.81953527301129059,\n",
      "     0.80589423784325431,\n",
      "     0.78602596561378812,\n",
      "     0.68611350427640316,\n",
      "     0.56978827050565117])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# you are on the right track if test_msas_df doesn't complain\n",
      "test_msas_df(msas_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# code to save your dataframe to a CSV\n",
      "# upload the CSV to bCourses\n",
      "# uncomment to run\n",
      "# msas_df.to_csv(\"msas_2010.csv\", encoding=\"UTF-8\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load back the CSV and test again\n",
      "# df = DataFrame.from_csv(\"msas_2010.csv\", encoding=\"UTF-8\")\n",
      "# test_msas_df(df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Bay Areas Diversity"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#find bay area diversity\n",
      "msas_df[msas_df.Name.str.contains(\"San Francisco\")]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Total</th>\n",
        "      <th>White</th>\n",
        "      <th>Black</th>\n",
        "      <th>Asian</th>\n",
        "      <th>Hispanic</th>\n",
        "      <th>Other</th>\n",
        "      <th>met_group</th>\n",
        "      <th>Name</th>\n",
        "      <th>p_White</th>\n",
        "      <th>p_Black</th>\n",
        "      <th>p_Asian</th>\n",
        "      <th>p_Hispanic</th>\n",
        "      <th>p_Other</th>\n",
        "      <th>entropy5</th>\n",
        "      <th>entropy4</th>\n",
        "      <th>entropy_rice</th>\n",
        "      <th>gini_simpson</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>met_group</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>41860</th>\n",
        "      <td> 4335391</td>\n",
        "      <td> 1840372</td>\n",
        "      <td> 349895</td>\n",
        "      <td> 994616</td>\n",
        "      <td> 938794</td>\n",
        "      <td> 211714</td>\n",
        "      <td> 41860</td>\n",
        "      <td> San Francisco-Oakland-Fremont, CA Metro Area</td>\n",
        "      <td> 0.4245</td>\n",
        "      <td> 0.080707</td>\n",
        "      <td> 0.229418</td>\n",
        "      <td> 0.216542</td>\n",
        "      <td> 0.048834</td>\n",
        "      <td> 0.859532</td>\n",
        "      <td> 0.901183</td>\n",
        "      <td> 0.891526</td>\n",
        "      <td> 0.711379</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "             Total    White   Black   Asian  Hispanic   Other met_group  \\\n",
        "met_group                                                                 \n",
        "41860      4335391  1840372  349895  994616    938794  211714     41860   \n",
        "\n",
        "                                                   Name  p_White   p_Black  \\\n",
        "met_group                                                                    \n",
        "41860      San Francisco-Oakland-Fremont, CA Metro Area   0.4245  0.080707   \n",
        "\n",
        "            p_Asian  p_Hispanic   p_Other  entropy5  entropy4  entropy_rice  \\\n",
        "met_group                                                                     \n",
        "41860      0.229418    0.216542  0.048834  0.859532  0.901183      0.891526   \n",
        "\n",
        "           gini_simpson  \n",
        "met_group                \n",
        "41860          0.711379  "
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "msas_sorted = msas_df.sort_index(by=\"entropy_rice\", ascending=False).head()\n",
      "plt.bar("
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Total</th>\n",
        "      <th>White</th>\n",
        "      <th>Black</th>\n",
        "      <th>Asian</th>\n",
        "      <th>Hispanic</th>\n",
        "      <th>Other</th>\n",
        "      <th>met_group</th>\n",
        "      <th>Name</th>\n",
        "      <th>p_White</th>\n",
        "      <th>p_Black</th>\n",
        "      <th>p_Asian</th>\n",
        "      <th>p_Hispanic</th>\n",
        "      <th>p_Other</th>\n",
        "      <th>entropy5</th>\n",
        "      <th>entropy4</th>\n",
        "      <th>entropy_rice</th>\n",
        "      <th>gini_simpson</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>met_group</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>46700</th>\n",
        "      <td>   413344</td>\n",
        "      <td>  168628</td>\n",
        "      <td>   58743</td>\n",
        "      <td>   59027</td>\n",
        "      <td>   99356</td>\n",
        "      <td>  27590</td>\n",
        "      <td> 46700</td>\n",
        "      <td>                  Vallejo-Fairfield, CA Metro Area</td>\n",
        "      <td> 0.407960</td>\n",
        "      <td> 0.142116</td>\n",
        "      <td> 0.142804</td>\n",
        "      <td> 0.240371</td>\n",
        "      <td> 0.066748</td>\n",
        "      <td> 0.897416</td>\n",
        "      <td> 0.926901</td>\n",
        "      <td> 0.911537</td>\n",
        "      <td> 0.730745</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>41860</th>\n",
        "      <td>  4335391</td>\n",
        "      <td> 1840372</td>\n",
        "      <td>  349895</td>\n",
        "      <td>  994616</td>\n",
        "      <td>  938794</td>\n",
        "      <td> 211714</td>\n",
        "      <td> 41860</td>\n",
        "      <td>      San Francisco-Oakland-Fremont, CA Metro Area</td>\n",
        "      <td> 0.424500</td>\n",
        "      <td> 0.080707</td>\n",
        "      <td> 0.229418</td>\n",
        "      <td> 0.216542</td>\n",
        "      <td> 0.048834</td>\n",
        "      <td> 0.859532</td>\n",
        "      <td> 0.901183</td>\n",
        "      <td> 0.891526</td>\n",
        "      <td> 0.711379</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26420</th>\n",
        "      <td>  5946800</td>\n",
        "      <td> 2360472</td>\n",
        "      <td>  998883</td>\n",
        "      <td>  384596</td>\n",
        "      <td> 2099412</td>\n",
        "      <td> 103437</td>\n",
        "      <td> 26420</td>\n",
        "      <td>         Houston-Sugar Land-Baytown, TX Metro Area</td>\n",
        "      <td> 0.396931</td>\n",
        "      <td> 0.167970</td>\n",
        "      <td> 0.064673</td>\n",
        "      <td> 0.353032</td>\n",
        "      <td> 0.017394</td>\n",
        "      <td> 0.796281</td>\n",
        "      <td> 0.876425</td>\n",
        "      <td> 0.873618</td>\n",
        "      <td> 0.685115</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35620</th>\n",
        "      <td> 18897109</td>\n",
        "      <td> 9233812</td>\n",
        "      <td> 3044096</td>\n",
        "      <td> 1860840</td>\n",
        "      <td> 4327560</td>\n",
        "      <td> 430801</td>\n",
        "      <td> 35620</td>\n",
        "      <td> New York-Northern New Jersey-Long Island, NY-N...</td>\n",
        "      <td> 0.488636</td>\n",
        "      <td> 0.161088</td>\n",
        "      <td> 0.098472</td>\n",
        "      <td> 0.229006</td>\n",
        "      <td> 0.022797</td>\n",
        "      <td> 0.805286</td>\n",
        "      <td> 0.876454</td>\n",
        "      <td> 0.872729</td>\n",
        "      <td> 0.672625</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>44700</th>\n",
        "      <td>   685306</td>\n",
        "      <td>  245919</td>\n",
        "      <td>   48540</td>\n",
        "      <td>   94547</td>\n",
        "      <td>  266341</td>\n",
        "      <td>  29959</td>\n",
        "      <td> 44700</td>\n",
        "      <td>                           Stockton, CA Metro Area</td>\n",
        "      <td> 0.358846</td>\n",
        "      <td> 0.070830</td>\n",
        "      <td> 0.137963</td>\n",
        "      <td> 0.388645</td>\n",
        "      <td> 0.043716</td>\n",
        "      <td> 0.828052</td>\n",
        "      <td> 0.869824</td>\n",
        "      <td> 0.862634</td>\n",
        "      <td> 0.694223</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "              Total    White    Black    Asian  Hispanic   Other met_group  \\\n",
        "met_group                                                                    \n",
        "46700        413344   168628    58743    59027     99356   27590     46700   \n",
        "41860       4335391  1840372   349895   994616    938794  211714     41860   \n",
        "26420       5946800  2360472   998883   384596   2099412  103437     26420   \n",
        "35620      18897109  9233812  3044096  1860840   4327560  430801     35620   \n",
        "44700        685306   245919    48540    94547    266341   29959     44700   \n",
        "\n",
        "                                                        Name   p_White  \\\n",
        "met_group                                                                \n",
        "46700                       Vallejo-Fairfield, CA Metro Area  0.407960   \n",
        "41860           San Francisco-Oakland-Fremont, CA Metro Area  0.424500   \n",
        "26420              Houston-Sugar Land-Baytown, TX Metro Area  0.396931   \n",
        "35620      New York-Northern New Jersey-Long Island, NY-N...  0.488636   \n",
        "44700                                Stockton, CA Metro Area  0.358846   \n",
        "\n",
        "            p_Black   p_Asian  p_Hispanic   p_Other  entropy5  entropy4  \\\n",
        "met_group                                                                 \n",
        "46700      0.142116  0.142804    0.240371  0.066748  0.897416  0.926901   \n",
        "41860      0.080707  0.229418    0.216542  0.048834  0.859532  0.901183   \n",
        "26420      0.167970  0.064673    0.353032  0.017394  0.796281  0.876425   \n",
        "35620      0.161088  0.098472    0.229006  0.022797  0.805286  0.876454   \n",
        "44700      0.070830  0.137963    0.388645  0.043716  0.828052  0.869824   \n",
        "\n",
        "           entropy_rice  gini_simpson  \n",
        "met_group                              \n",
        "46700          0.911537      0.730745  \n",
        "41860          0.891526      0.711379  \n",
        "26420          0.873618      0.685115  \n",
        "35620          0.872729      0.672625  \n",
        "44700          0.862634      0.694223  "
       ]
      }
     ],
     "prompt_number": 41
    }
   ],
   "metadata": {}
  }
 ]
}